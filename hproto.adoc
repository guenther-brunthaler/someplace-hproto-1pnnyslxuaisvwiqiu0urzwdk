hproto - Human-friendly binary protocol message encoding
========================================================
Guenther Brunthaler
v2021.3

Introduction
------------

hproto is a binary protocol message encoding similar to Google's "protocol buffers", "MessagePack", "BENCODE" "ASN.1", "XDR" or the author's own "aproto".

It is used by a sending process to encode ("marshal") the data structure of a software message as an opaque block of binary data, which can then be transferred by any means available to a receiving process, which decodes ("un-marshals") and re-assembles an equivalent message for local processing.

The scope of application for hproto is also similar to that of XML, YAML, RFC-822 and JSON, except that hproto is not a text-based encoding.

The outstanding property of hproto is the fact that the encoding is simple enough that an encoded message can be decoded by a human with the help of a hexadecimal dump of the message contents relatively easily.

In this regard, hproto is similar to BENCODE, although the actual encoding is much more similar to "protocol buffers".

Like MessagePack, hproto also sacrifices some encoding efficiency for simplicity, resulting in an encoding which is less compact than "protocol buffers" or "aproto", but not by much.

hproto has also some provisions for optionally allowing to define messages in such a way so that they can be modified in-place. This is not as powerful als Google's "flatbuffers" which have been created explicitly for this purpose, but also much simpler to implement and understand.


Quick examples
--------------

hproto encodes a message by emitting the encodings of all the fields in the message. The following examples will only show messages consisting of a single field.

Every field is encoded by a dump of its encoded data, preceded by a control octet which specifies the field name (as an associated numeric tag value) in its most significant nybble (4 bits), and the octet count of the encoded dump in its least significant nybble.

All examples here use the same field name, which is associated with the arbitrary numeric tag value 12 (0x0c in hexadecimal).

Hex dump of the encoding for integer 3 as field value:

....
c1 03
....

The first octet is the control octet where 'c' encodes the tag value 12, and '1' is the byte count of the data part of the encoding. The last octet contains the data part of the encoding, its octet value represents the encoded integer value.

Encoding of integer value 0x123:

....
c2 01 23
....

This is quite similar, but the encoded data part is 2 bytes now, which is also indicated by the least significant 4 bits of the control octet.

Naive encoding of integer 0:

....
c1 00
....

However, this can be shortened because there is a special rule: Numeric fields encoded as having an octet size of zero automatically represent value 0.

Therefore, integer 0 could be also encoded more efficiently as

....
c0
....

Encoding of ASCII string "Hello":

....
c5 48 65 6c 6c 6f
....

The initial control octet reflects the octet size of the data part in its low-order nybble, 5 octets in this case because there are 5 ASCII characters. The remaining 5 octets of the data part just represent the ASCII dump of the string itself.

Note that the fact that this is an ASCII string rather than an integer value cannot be known from the encoding itself. This knowledge instead comes from the associated protocol definition, which in this case would define the field with tag number 12 as representing an ASCII string.

Encoding of signed integer ("int") -0x1234567:

....
c4 81 23 45 67
....

Signed integers are encoded in hproto by reserving the leftmost bit of the data hex dump as a sign bit. The value itself is always stored in absolute form, i. e. as a positive value. The sign bit then decides whether this positive value shall actually be negated when decoding.

Encoding if signed integer -0xaaaa:

....
c3 80 aa aa
....

In this case it was necessary to add a third octet to the left of the data part for storing the sign bit, because the leftmost bit of the 2-octet representation of the value was already in use by the value itself, and could therefore not be re-purposed as a sign bit.

In order to avoid negative zero, there is a special rule: The encoding which would represent -0 shall instead represent its negated own literal value.

That is, the signed integer encoding of

....
c1 80
....

does not represent -0 but rather -0x80, because 0x80 is the literal value of the encoding, and -0x80 is that value negated.

Note that this does not forbid to encode -0x80 less efficiently as

....
c2 80 80
....

but encoders should prefer the shorter encoding, making use of the special rule.

By making use of the rule, the hproto encodings of all signed integers will always have the same (or shorter) size than the traditional 2's complement encoding of the same integer.

For instance, a fixed 32-bit signed integer variable containing the value -1 would represented as 'ff ff ff ff' in memory, but hproto can encode it shorter as

....
c1 81
....

which is the positive value 0x01 with the sign-bit set (which adds 0x80).

One might wonder what hproto does if the tag number is larger than 15 or when the data part is longer than 15 bytes.

For those cases, an extension mechanism has been put in place.

The last 2 values of the "tag" nybble and the last 4 values of the "length" nybble are reserved for that extension mechanism.

If a value reserved for the extension mechanism is used in either nybble of the control octet, then extension fields are inserted after the control octet, and the nybble values specify the octet size of the inserted extension fields.

In this case, the extension field contents represent the actual values which were too large to be represented as nybble values.

In the case of the "tag" nybble, the 2 reserved values specify the size of the extension field linearly: 0xe means 1 octet and 0xf means 2 octets as the size of the inserted extension field for the "tag" value.

That is, the encoding for integer 5 which does not need an extension field for its tag value 0x0c

....
c1 05
....

could also be encoded less efficiently using an inserted one-byte extension field for the tag value as

....
e1 0c 05
....

where the '`e`'-nybble of `0xe1` tells the reader that the following `0x0c` octet is an extension field containing an 8-bit tag value, `0x0c` in this case.

The '`1`'-nybble of `0xe1` is not a value indicating an extension field, and so it just represents the data part length of `1` octet (which is the `0x05` that follows the extension field).

or even less efficiently using an inserted two-byte extension field

....
f1 00 0c 05
....

This is pretty much the same, except that the extension field is now 2 octets wide and contains the value 0x000c.

But the relative order between the parts of the encoding are the same: The control octet first, then its extension fields if any, finalle the data part.

Note that the insertion of the extension field did not change the byte count of the data part - it is still just one octet in both cases.

Also note that the extension fields are encoded as big-endian integers, just like all values in hproto. This is because big-endian numbers are more human-friendy to read than little-endian numbers in a hex dump.

Another reason is encoding-friendlyness: hproto messages are built starting at the end of the buffer with descending the write offsets for the next output byte. Which means the numbers are written in reverse, that is as little-endian encoding which is easier to do for encoders. The decoder however reads the encoding starting at its beginning, and therefore sees big endian numbers which are easier to process by decoders.

The third reason for encoding the output buffer in reverse direction is the fact that it allows the encoding to use a one-pass scheme without sacrificing encoding-efficiency: At the time when the length of a field has to be encoded, its actual length is already known exactly. This makes it easy to choose the shortest possible encoding variant, which would be impossible in a single pass otherwise.

In the case of 'length' nybble, the 4 reserved values specify the size of the extension field as a power of 2: 0xc means 1 octet, 0xd means 2 octets, 0x0e means 4 octets, and 0x0f means 8 octets.

That is, the encoding of integer `6` which does not need an extension field for its octet count of `1`

....
c1 06
....

could also be encoded less efficiently using an inserted one-byte extension field for the 'length' field as

....
cc 01 06
....

or even less efficiently using a two-byte 'length' extension field

....
cd 00 01 06
....

or with a 4 byte length

....
ce 00 00 00 01 06
....

or even with an 8 byte extension field for the length

....
cf 00 00 00 00 00 00 00 01 06
....

It is possible that both extension fields are present, one for the tag and one for the length. In this case, the extension field for the tag comes first (lower address) and the length extension field comes second (higher address). That relative order is easy to remember, because it is the same relative order as the associated nybbles within the control octet.

Both extension fields are then inserted between the actual data-part and the control octet.

Encoding of ASCII string "Hello, world" (with a size of 12 octets, its last octet has value `0x64`) as a field with field tag number `0x1234`:

....
fc 12 34 0c 48 65 6c 6c 6f 2c 20 77 6f 72 6c 64
....

To break this down for decoding, markers could be inserted as follows:

....
fc | 12 34 | 0c | 48 65 6c 6c 6f 2c 20 77 6f 72 6c 64
....

Control octet `0xfc` specifies that a 2-octet 'tag' extension field and a 1-octet 'length' extension field is present.

The 2 octets '`12 34`' represents the field 'tag' number, and the '`0c`' represents the 'length' of the data-part.

The remaining octets after that which end with value 0x64 represent the data-part (i. e. the payload of the field).

As explained before, messages are just a concatenation of the message field encodings.

Therefore, a 3D-vector could be encoded as a message consisting of 3 signed integer fields, where the "x"-field is represented by tag value 0, "y" as value 2 and "z" as value 3.

Encoding the co-ordinates (-2, +0x113854, -0x10) as such a message then results in

....
01 82 13 11 38 54 21 90
....

To break this down for decoding, the control-octets could be enclosed within brackets as

....
[01] 82 [13] 11 38 54 [21] 90
....

This shows clearly what the data-part of the encoding is, and what the control-part (control octets and their optional extension fields) is.

The encoding explained so far is easy to parse from the beginning, but there is no way how to indicate its end. This needs to be known by the decoder.

Typically, the decoder will be presented with a fixed-size message for decoding, so determining the end is not a problem.

But what if the data arrives as a stream instead of a sequence of records with known size?

There are three recommended solutions for such a case.

First, the protocol can define a specific 'tag' value to serve as an end-of-stream marker. It usually will not need any associated data, which means the 'length' nybble will be `0`. Then the decoder has decoded such a tag value, it will know the end of the message has been reached and will stop decoding any further data at this point.

The second solution is to prefix the message encoding with the size of the message. This simple message framing mechanism within data streams works as follows:

....
02 c1 42
....

frames the hproto-encoded message consisting of "c1 42" by prefixing it with the message length, which is two octets in this case.

This kind of prefixing works very similar to the 'length' nybble, only that it is not just a nybble but rather a whole octet. It is thus a similar but different kind of control octet compared to core hproto-encoding.

And also the same as for the length nybble, the last 4 values are set aside to encode extension field lengths in the same way as for the nybble.

This means the following values are used for the message framing prefix octet:

* 0x00-0xfb: The value represents the message length directly as one octet.
* 0xfc: The message length follows as a 1-octet extension field
* 0xfd: The message length follows as a 2-octet extension field
* 0xfe: The message length follows as a 4-octet extension field
* 0xff: The message length follows as a 8-octet extension field

In all cases, the framed message follows the message length field with the indicated length.

It may seem doubtful that 0xfc will be very useful. It would have been better to only set aside 3 special values and start with the 2-octet case.

But as this is a human-friendly protocol, it should be easy to remember. Also reserving 4 codes here in the same way as for the length nybble is easier to remember. And so we do it that way!

The third an final solution to the stream-decoding "unknown message size"-problem would be to only encode a single binary string as the message. This string actually contains the nested hproto-encoding of the actual message components. But at the outer level it is just one encoded string. So the encoder only needs to be instructed to not decode more than one message at the top-level and then stop.


Protocol definition syntax
--------------------------

Like "protocol buffers", hproto provides a metasyntax for defining the structure of a message. This information needs to be known by both the sender and receiver of a message in order to understand the contents of the message.

"protocol buffers" uses ".proto" text files for storing this metasyntax information, while hproto uses - little surprisingly - ".hproto" files for the same purpose.

It should be possible to write a message compiler for .hproto files which can validate the syntax of those files and then synthesize code for automatic marshalling and unmarshalling of hproto messages.

But this has not been done yet and may never be done, because hproto is simple enough that it can be assembled mostly manually. It can also be decoded visually using only a hex dump of the encoded message and a copy of the associated .hproto file as a reference.

OK, and now for an example how hproto works. Let's assume we have the follwing C struct

----
struct person {
   char *first_name, *last_name;
   unsigned int born;
}= {"John", "Doe", 1990};
----

and want to encode/serialize it as binary hproto message blob ("binary (potentially) large object") for transport.

First, we create a file "person.hproto" for this message, containing the following definition:

----
message person {
   string first_name:0;
   string last_name:1;
   uint born:2;
};
----

This defines the fields which are allowed in the message and also assigned numeric field tag numbers to every field.

The syntax for the field numbers looks similar to that of bit fields in C. However, it is recommended not to put a space between the field number and the field name, because otherwise the inclusion of a default value (explained later) might look ugly.

The tag numbers should be thought of as name suffixes rather than independent properties of the message field definitions.

Other than the field names which are only required in the proto files, the field tag numbers will actually be part of the encoded binary message as "tags numbers".

Also note that the field/tag numbers must be specified as hexadecimal values, even though there is no `0x`-prefix allowed for values up to 9, yet such a prefix is required for values larger than 9. The reason for the requirement of hexadecimal tag numbers is that a hex dump of the encoded message will also show hexadecimal tag numbers. By defining them them in the same way in the protocol definition, not conversion between decimal and hexadecimal tag numbers will be needed.

Next, one needs to know the encoding of a hproto message.

In this simple case, all fields can be encoded by writing their encoded values prefixed by a <type_octet> in which the high-nybble represents the field tag number and the low-nybble represents the length of the encoded field contents.

The last thing to know for this example is how to encode the data types "string" and "uint".

Note again that messages are encoded starting at the end of the buffer. The order in which the fields are present in the message does not really matter in this case, because every field has its own tag value and so the decoder exactly always knows which field name is associated with the field and into which `struct` field to put the decoded value.

However, as the encoding is supposed to be human-friendly, it is recommended to serialize the fields in the reverse order in which they appear in the protocol definition.

This will then result in the original field order in the encoded message, because decoding will start at its beginning rather than at its end.

This means we should encode the 'born:2' field first, because it comes last in the message definition.

So we need to encode the value 1990 as type "uint" and associate it with the field number 2 as its tag value.

Im hproto, "'uint'" is just the big-endian base-256 representation of the unsigned integer. As a special optimization, an 'uint' with a data portion size of 0 bytes is allowed and then represents the numeric value zero. (This might be a very useful optimization, because zero is a very frequent value in many applications.)

Next we need to know that "big-endian base-256 representation" is just a pompous way of saying that the hex dump of the encoded unsigned integer looks exactly the same as the integer written as a multi-digit hexadecimal number with a leading "0" digit in case of an odd number of hexadecimal digits in the multi-digit representation.

Example: Hex integer `0x1a` will encode as hex dump "`1a`", `0xf` will encode as hex dump "`0f`", `0x12345` will encode as hex dump "`01 23 45`" etc. Simple!

With that knowledge, we now can encode the 'born:2' field:

----
$ # uint born:2; /* 1990 */
$ printf '%x\n' 1990
7c6
----

We encode this as the hex bytes

....
22 07 c6
....

where the "07 c6" are the hex dump for the decimal value 1990 expressed in hexadecimal (0x7c6).

The left "2" in the trailing "22" is the field number of 'born:2' (the numeric suffix of its field name). The right "2" is the length of the field in octets.

This leaves us with the end of the encoded message as constructed so far:

....
22 07 c6
....

The next field we have to encode because of the reverse ordering is

----
string last_name:1;
----

and its contents shall be "`Doe`".

The encoding of a "string" is simple - the data part of the encoding is just the bytes which make up the string.

We serialize the data part first

----
$ # string last_name:1; /* "Doe" */
$ printf %s Doe | hexdump -C
00000000  44 6f 65                                          |Doe|
00000003
----

We encode this as the hex bytes

....
13 44 6f 65
....

The "`1`" in the initial "`13`" is the field tag for "`last_name`". The "`3`" is the length of the string.

We prepend this new encoding before the start of the message already encoded so far, getting

....
13 44 6f 65 22 07 c6
....

as the new message constructed so far.

Finally, we encode the first field (according to protocol definition field order) "`first_name`":

----
$ # string first_name:0; /* "John" */
$ printf %s John | hexdump -C
00000000  4a 6f 68 6e                                       |John|
00000004
----

We encode this as the hex bytes

....
4a 6f 68 6e
....

and prefix this with the control octet `0x04`, because the field tag is 0 and the field contents (data portion) length is 4, giving:

....
04 4a 6f 68 6e
....

As before, we prepend this field encoding to the whole message encoded so far, getting

....
04 4a 6f 68 6e 13 44 6f 65 22 07 c6
....

as the finally completed encoded hproto message.

For decoding this message, one has to start from the right and cut the message into fields based on the length of the field's control octets:

....
[04] 4a 6f 68 6e | [13] 44 6f 65 | [22] 07 c6
....

I have used "|" here to show field boundaries and put the control octets within square brackets.

Now for another example: Given the hproto definition

----
message coord3d {
   int x:0;
   int y:1;
   int y:2;
};
----

decode the following encoding for an instance of such a message:

....
01 4a 10 21 8b
....

Let's start decoding by adding field markers as visual clues:

....
[01] 4a | [10] | [21] 8b
....

and decode this as:

field #0 ("x") = int_decode(0x4a) = 37
field #1 ("y") = int_decode(0x00) = 0
field #2 ("z") = int_decode(0x8b) = -11

Where came the 0x00 for field "y" from? Well, as explained before, a zero-sized numeric fields (such as "int") represents the numeric value zero even though no space for the actual value has been included in the message.

Why is the decoding of 0x8b the value -11? Remember that hproto does not use 2's complement numbers because those are not human-friendly. It just adds a '1' bit at the most significant octet of the encoding, which is the same as adding the value 0x80. This means the encoded value `0x8b` is actually the sum of `0x80' for the negative sign plus the absolute value `0x0b` of the actual value to be encoded. `0x0b` is `11` as decimal number, and the negative sign makes it `-11` as the decoded result.

So, the message decodes as

----
message coord3d {
   int x:0;
   int y:1;
   int y:2;
}= {37, 0, -11};
----


A historic note about the reverse encoding direction
----------------------------------------------------

A previous version of hproto did things exactly the other way around: The decoder wrote starting at the beginning of the buffer, so it was easy to grow it using realloc if necessary without moving the already-encoded parts of the buffer after the reallocation.

However, the disadvantage was that now decoders needed to start decoding at the end of the buffer, moving towards decreasing offsets as the decoding progressed.

Also, the control octets and extension fields had to be placed after the data portion of the fields instead of before them, raising questions whether the order of the extension fields should also be reversed or not.

Furthermore, it was even more problematic to read a message from a stream of unknown size, because the framing solution was the only one which could possibly work. The other 2 solutions only work when starting the decoding process at the beginning of the buffer - but this was not the case.

The next problem was encoding of integers: Because they ought to be placed in big-endian byte order within the encoding, they also had to be encoded in this order when using ascending offsets by the encoder. This is bascically a 2-step process: Determine the necessary length first, and then write out the octets in that order. An alternative is to write the octets in little-endian order first, and then reverse the order.

The new approach eliminates this problem, because the octets can now be written out in little-endian order, which results in big-endian order within the encoded message due to the fact that the writing occurs in decreasing offset order.

But most of all, decoding something backwards is not human-friendly.

So, after careful consideration, the encoding process was reversed, yielding to encoded messages which seem more "natural" to a human reader.

The only real disadvantage is that the new scheme requires a memmove() after a realloc() when the message is growing and the currently allocated buffer turns out to be too small.

The old approach did not need to move the data to the new end of the buffer, because the data already written was located at the beginning of the buffer.

However, I think the numerous benefits of the new approach compensate for this single disadvantage.

Also, reallocation will most likely occur only rarely in practice, assuming the buffer will be grown by a power of 2 factor or similarly. Which means reallocation will occur less and less frequently the larger the buffer gets.

Finally, realloc() probably has a lot more overhead than a single memmove(), so the actual overhead of the new machanism will likely be rather small in comparison.


hproto Message "wire" Encoding
------------------------------

Examples are fun. But now for the full picture!

A hproto message encoding is an unordered collection of fields, much more like a hash rather than a C "struct". The fields within the message are identified by their tag number rather than by their order.

The actual message encoding is just a concatenation of field value encodings.

Decoding starts at the beginning of the encoded message, but hproto does not provide an intrinsic machanism for detecting the end of the message.

This length must be known in advance, which will be the case for all message- or packet-oriented transports.

However, it will not be known in advance when reading from a stream, such as from a serial line or from a pipe.

For those cases, 3 solutions are possible:

* Change to protocol so that the whole message will be nested within a single binary string field. The decoder can then be instructed to decode only this single field and then stop.

* Define a tag value as an optional message field with no data contents. The decoder can then be instructed to stop decoding as soon as such a field has been decoded, acting as an end-of-message indicator.

* Use message framing, prefixing the message with its octet size.

Message framing is encoded as follows:

....
[ <size_of_encoded_actual_message> ] <encoded_actual_message>
....

If such a size prefix shall be present and how many bytes shall be used for encoding it (as a base-256 big-endian unsigned integer) must be defined in the protocol definition. There is no such prefix by default.

The size itself is encoded the same way as the field length in a control octet, except that all 8 bits are used and not just 4. However, in both cases, the last 4 possible values are reserved as length extension codes, and the encode the extension field lengths as 1, 2, 4 or 8 octets. The extension field, if present, then stores the actual message size as an unsigned integer in big-endian byte-order.

Within the actual encoded message, each field value encoding has the following structure:

....
<type_octet> [ <external_tag> ] [ <external_length> ] <field_contents>
....

Only <type_octet> and <field_contents> are actually necessary for every field, and <field_contents> has a variable size which can also be zero.

<type_octet> consists of two bitfields with 4 bits each, which will be represented by single hex-digits in a hexdump of the message:

* The left hex-digit of <type_octet> encodes the tag number of the field.
* The right hex-digit of <type_octet> encodes the byte size of the field contents.

The tag number is encoded directly within <type_octet> if its value is less than 0x0e. Otherwise, <external_tag> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the field contents (data part, payload) is encoded directly within <type_octet> if its value is less than 0x0c. Otherwise, <external_length> is present and contains the actual tag number as a big-endian base-256 unsigned integer.

The byte size of the <external_tag> field itself is determined by the value of the left hex-digit in <type_octet>: 1 if it is 0x0e, 2 if it is 0x0f, 0 otherwise.

The byte size of the <external_length> field itself is determined by the value of the right hex-digit in <type_octet>: 1 if it is 0x0c, 2 if it is 0x0d, 4 if it is 0x0e, 8 if it is 0x0f, 0 otherwise.

Maybe it might be easier to remember that the last 2 representable values of the "tag" nybble are reserved for specifying the length of the tag value extension field, and the last 4 representable values of the "length" nybble are reserved for specifying the length of the octet count extension field as a power of 2.

That's all one needs to know for the encoding of the basic message structure!


Optional message size specifications
------------------------------------

As explained before, it is optionally possible to prefix the actual message encoding with its size, for cases where the exact message size will not be provided by the transport and the message-framing solution has been chosen.

In this case, the following statement shall be precede any message declarations in the `.hproto` file:

----
option size-prefixed top-level message;
----

If the protocol designer preferred the other solution of defining an end-of-stream marking tag-value, the following statement shall be used instead:

----
option end-of-message tag value is N;
----

where N is a hexadecimal tag value which will be used by the decoder as an instruction to stop decoding after the current field when encountered as a field's tag value. Regarding the presence of a "`0x`"-prefix, the same rules are used as for tag values in message field definitions.

If the protocol designer preferred the solution to wrap the whole message into a single binary string field or into a single message containing everything else as sub-fields, then the following statement shall be used:

----
option message consists of a single top-level field;
----

Without any of those options, the message size needs to be known in advance to the decoder.


I have an 8-bit CPU, I do not want to support 64-bit field sizes
----------------------------------------------------------------

You don't have to! The fact that hproto messages can contain 64-bit wide size fields does not mean that every conforming application has to support those.

In fact, every hproto implementation is free to typedef a type of its choice for internally storing field sizes.

For instance, an 8-bit implementation may decide to not support any field lengths wider than 8 bits.

Such an implementation must still recognize that a messages includes a 16-, 32- or 64-bit size field if this is the case.

But it is free to reject the reception of such a message with an error message, stating that the message contents exceed the application's limits or that the message itself is too large to be parsed completely let alone to be actually processed.

In fact, even 64-bit implementations of hproto should reject messages of unreasonable sizes. Because otherwise the application could become a victim of dDoS-attacks where an attacker sends gigantic messages until the victim runs out of RAM.

Receivers and senders of hproto messages should share an idea what amount of data to maximally expect in a message, and should refuse to accept messages larger than that. 

Rejecting messages assumes some sort of back-channel for status messages of course.

In situations where this is not possible such as using UDP, applications should just ignore messages which are too large or contain field widths for sizes they cannot handle. After all, UDP does not guarantee any reception at all. So the receiver is free to pretend it never got the message.


Optional buffer-size restriction
--------------------------------

Sometimes it is a good idea to specify the maximum buffer space a message may consume.

Receivers then know what to expect in the worst case, and can even allocate the buffer in advance if the size seems small enough, avoiding subsequent reallocations of the buffer.

Such a declaration should follow any "size-prefix"-declaration and precede any field definitions in a message. The declaration has the following syntax:

----
maximum buffer size only at top-level is N octets;
----

This is similar to the "size-prefix" declaration but serves an entirely different purpose. Like "size-prefix" it only has an affect if a the messages is used as the top-level message and is ignored for nested messages.

This declaration is partially forward-compatible: It is never a problem to add such a declaration for a later protocol revision, because without this declaration there is no limit how large the message could potentially become. It is up to the receivers to reject messages too large for them.

Neither is it a problem to reduce the limit in later protocol revisions: Clients which still use the old revision will never receive messages larger than that.

But if you increase the declared maximum buffer size in later revisions, clients using older protocol revisions may reject new messages as being too large.

Note that clients are not forced to check whether the size of received messages conforms to the message definition. They might choose to ignore it. Or they might check indeed, and senders should be prepared for this case.

Also note that the declaration is about the maximum buffer size and not about the maximum "actual message"-size. This means that the buffer space required for the size-prefix, if any, must also be included in the declared maximum buffer size.

Finally, the maximum buffer size implicitly puts the same maximum limit to all message fields and nested messages.

This means it is not necessary to specify maximum sizes for individual message fields; the maximum-buffer size also puts an upper bound to the sizes of all the individual fields.


What happens if multiple fields have the same tag number
--------------------------------------------------------

In this case, the field is considered to contain a vector of elements with the field's defined type rather than a single field element.

Of course, "multiple fields" are interpreted that way only within the same message, not within nested messages or a parent message containg the current message. In the latter cases, the fields belong to different messages and do not represent a vector.

Only multiple fields with the same tag number within the same message instance represent a vector.

For a vector, only the relative order of vector elements is relevant for indexing the vector, there is no need for them to be contiguous within the message.

For instance, consider this message encoding:

....
[11] 11 | [21] 22 | [31] 33 | [21] 44 | [11] 55 | [21] 66
....

then this represents the following messsag fields:

...
tag 1: vector[0x11, 0x55]
tag 2: vector[0x22, 0x44, 0x66]
tag 3: scalar 0x33
...

There is no actual difference between a scalar and a 1-element vector - the application can interpret it any way as it likes.

But what shall be done if the application expects a scalar and a vector is encountered instead?

In this case, the decoder shall ignore all values except for the last vector element. That shall be used as the scalar value.


More example field contents encodings
-------------------------------------

The encodings in our first examples have been easy because all tag numbers and field contents lengths could be represented directly within <type_octet> and neither <external_tag> nor <external_length> where required.

So let's define a more complex message which needs both extended fields:

----
struct person2 {
   char *first_name;
   char *last_name;
   struct bigint *favorite_fermat_prime;
}= {
     UTF7_2_UTF8("G+APw-nther"), "Brunthaler"
   , STR_2_BIGINT("162259276829213363391578010288127")
}

message person2 {
   utf8_string first_name:8;
   utf8_string last_name:0x23;
   uint favorite_fermat_prime:0x4567;
};
----

We use the type "utf8_string" here instead of just "string", because we want to use a particular encoding (UTF-8) for the contents of the string.

Note that we can actually use any types we want in the .hproto message definitions, because there is no compiler/verifier for it yet. It is strictly provided as a documentation of the intended message layout for the benefit of human developers.

As one can see, the field number tags in the hproto files must actually be provided as hexadecimal numbers. This was not obvious in our previous example because we only used tag numbers no larger than 9, which are the same in decimal and hexadecimal and which are not allowed to use a `0x`-prefix.

The reason why field numbers must be provided in hexadecimal is the fact that you will also see them in this form in the hex dump of a message.

The reason why there is no choice when to use the "`0x`"-prefix and when not is because it allows search for field-names and their hexadecimal suffixed using simple string search tools. If there was a choice whether to include the prefix or not, a simple string search would not suffice and regular expressions would be needed. And, by the way, all hexadecimal numbers must be specified in lower case in hproto files for the same reason!

We also remember from the explanation of the field number encoding that there are actually 3 different classes of field numbers which are encoded differently:

* type_octet "Nx" with <internal_tag> N from 0x00 through 0x0d
* type_octet "ex" NN with <external_tag> NN from 0x00 through 0xff
* type_octet "fx" NN NN with <external_tag> NNNN from 0x0000 through 0xffff

where "x" does not matter in this discussion (it represents the field length).

Now let's encode the actual fields:

----
$ # utf8_string first_name: 8 = UTF7_2_UTF8("G+APw-nther")
$ printf %s G+APw-nther | iconv -f UTF-7 -t UTF-8 | hexdump -C
00000000  47 c3 bc 6e 74 68 65 72                           |G..nther|
00000008
----

These are 8 UTF-8 bytes with field tag 8, which will be encoded as

....
[88] 47 c3 bc 6e 74 68 65 72
....

----
$ # utf8_string last_name: 0x23 = "Brunthaler"
$ printf %s Brunthaler | iconv -t UTF-8 | hexdump -C
00000000  42 72 75 6e 74 68 61 6c  65 72                    |Brunthaler|
0000000a
----

This are 0x0a bytes with field tag 0xe23, which will be encoded as

....
[ea | 23] 42 72 75 6e 74 68 61 6c 65 72
....

I have used here the square brackets not only to enclose the control octet, but the extension fields as well. The control octet and the fields are separated by "|", which will also be used to separate the encoding of different fields (outside the square brackets).

In the above encoding, the "23" is the <external_tag> which is present because the "e" in the "ea" defines a 1-byte <external_tag> to be present. The "a" in the "ea" is the byte length of the UTF-8 encoded string, and the remaining bytes represent the string contents.

----
$ # uint favorite_fermat_prime: 0x4567 = STR_2_BIGINT("162259276829213363391578010288127"
$ echo "obase=16; 162259276829213363391578010288127" | bc | tr A-F a-f | { read x; expr ${#x} % 2 != 0 > /dev/null && x=0$x; printf '%02x\n' `expr ${#x} / 2`; echo $x | fold -w 2 | paste -s -d " "; }
0e
07 ff ff ff ff ff ff ff ff ff ff ff ff ff
----

The first line of the output is the number (0x0e) of the following bytes, and the second line is just the hexadecimal representation of the large prime number. We encode this as

....
[ fc | 45 67 | 0e ] 07 ff ff ff ff ff ff ff ff ff ff ff ff ff
....

The "f" in the "fc" means that we use a 2-byte <external_tag>, which is represented by the bytes "45 67" which are the big-endian base-256 representation of the value 0x4567.

The "c" in the "fc" means that the length of the contents is too large to be encoded directly as the 2nd hex digit of the <type_octet>. Instead, a 1-byte <external_length> is used to represent the actual length. This is the byte "0e" in the encoding. The remaining bytes represent the prime number as an unsigned integer with the value 0x07ffffffffffffffffffffffffff.

Now we append the individual field encodings to the final message, ordering them so that the fields have the same order as in the message definition.

Together, the complete message hproto-encodes as

....
88 47 c3 bc  6e 74 68 65  72 ea 23 42  72 75 6e 74
68 61 6c 65  72 fc 45 67  0e 07 ff ff  ff ff ff ff
ff ff ff ff  ff ff ff
....


Here is a chart for decoding hproto messages based on their hex dump (starting with the first byte of the actual message, after any size framing prefix):

* 0? - d?: Tag number is directly encoded as 0x00 through 0x0d.
* e?: Tag number precedes as 1 byte
* f?: Tag number precedes as 2 bytes (big-endian base-256 representation)
* ?0 - ?b: Field contents byte length is directly encoded as 0x00 through 0x0b.
* ?c: Contents length precedes as 1 byte
* ?d: Contents length precedes as 2 bytes (big-endian base-256 representation)
* ?e: Contents length precedes as 4 bytes (big-endian base-256 representation)
* ?f: Contents length precedes as 8 bytes (big-endian base-256 representation)

In all cases, the optional <external_tag> precedes the optional <external_length>, and both are located between <type_octet> and <field_contents>.

After those examples, some clarifications.

There are no "required" fields in a message. All fields can be missing, which will then behave like a "NULL" value in SQL (i. e. "value not present").

----
message person {
   string first_name:0;
   string last_name:1;
   opt married:2;
};
----

If the type "opt" has been defined as an empty message with no fields (encoded as "20" for tag number 2 and zero length) and the presence of the field means the option applies, then the missing field means that the option does not apply.

That is, the presence of a "20" field encoding as a message field means the person is married. Otherwise the person is not married.

It is also possible to define a default value in the hproto file. If the field is missing in the message, then the field is assumed to have the default value as its contents.

----
message person {
   string first_name:0;
   string last_name:1;
   string marital_status:2 = "single";
};
----

This means that if a field with tag number 2 is present then it represents the marital status as a string. Otherwise, the string "single" will be used as the status even though it is not actually present in the message and would be NULL without the default declaration.

When creating a message, a field can be omitted from the encoding if the value to be encoded equals the field's default value. This is just an optimization, though, and not a requirement.

So far, the length of the <field_contents> have always been determined by the minimum number of bytes required to represent the contents.

However, for messages which are to be edited in-place, it might be a good idea to make the field length that of the maximum supported length of the content.

For instance, if we want to store a 24-bit RGB color encoded as an unsigned integer 0xRRGGBB

----
message rgb_color {
   uint rgb24:9;
};
----

then the color black 0x000000 could easily be encoded as

....
90
....

(remember that an uint of size 0 represents the value zero) because 0x000000 and 0 are the same integer.

However, if we want to make this message editable in-place, we need to ensure that it will always use 3 bytes for the encoding, even if it means to store leading zeros, so that the value can be replaced with an arbitrary RGB value later.

This can be enforced as follows:

----
message rgb_color {
   uint rgb24:9 (zero-leftpad to 3 octets);
};
----

This means that if the field contents need less then 3 bytes to encode, then it will be padded to 3 bytes by adding zero bytes at the left. "zero-rightpad" does the same but adds the pad bytes at the right side (this type of padding is useful for strings).

The term "octet" is used instead of "byte" to make clear that 8-bit bytes are meant. Historically, bytes with bit sizes other than 8 bits are known to have existed on some hardware platforms. "octet" always means an "8 bit byte".

Generally, a comma-separated list of such and similar attribute declarations can be placed within parentheses before the end of the field declaration.

Like for tag numbers, only hexadecimal numbers are allowed for zero-rightpad declarations in order to avoid base conversions when examining the hexdump of a message. And again the 0x-prefix is forbidden for hex numbers up to 9.

In the case of this example, "3" means direct encoding within the <type_octet>. It ensures that the color black would be encoded as

....
93 00 00 00
....

The "9" is the tag number, the "3" is the field contents width directly encoded in the <type_octet>, and the "00 00 00" is the 24-bit fixed-width RGB encoding of black.

Another example:

----
message nested_string {
   string text:6;
};

message song {
   uint track:3 (zero-leftpad to 1 octet);
   nested_string artist:5 (zero-rightpad to 0x20 octets);
   nested_string title:7 (zero-rightpad to 0x40 octets);
   nested_string description:4 (zero-rightpad to 0x400 octets);
};
----

Such a message will have the following encoding:

....
31 <track_uint> 5c 20 <artist_string>...
7c 40 <title_string>... 4d 04 00 <description>... 
....

Note that the fields ending with "..." are nested fields which include their own length. The idea is that the "inner" length specifications define the actual length of the field contents, where the zero-rightpad width just ensures that there is enough space for increasing the inner length in-place.


include::field_data_types.txt[]
